{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa7388659b83a667"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b512389b39fe6b06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1164c349dcff8156"
  },
  {
   "cell_type": "markdown",
   "source": [
    "KMeans Clustering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "549c3f45365bf5d1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def k_means_cluster(train_data, num_clusters, epsilon):\n",
    "    # get number of features for each cluster and declare a 2d list cluster positions\n",
    "    num_features = train_data.shape[1]\n",
    "    centroids = np.empty((int(num_clusters), num_features))\n",
    "    # generate starter values for each of the features between the minimum and maximum values for that feature\n",
    "    for feature_index in range(num_features):\n",
    "        max_val = np.max(train_data[:, feature_index])\n",
    "        min_val = np.min(train_data[:, feature_index])\n",
    "        for centroid_index in range(centroids.shape[0]):\n",
    "            centroids[centroid_index][feature_index] = np.random.uniform(min_val, max_val)\n",
    "    # create a variable to track the total distance between old and new centroids\n",
    "    total_diff = 10\n",
    "    # this while loop keeps reassigning entries to centroids and adjusting the centroids accordingly until the\n",
    "    # centroids no longer move\n",
    "    # run this loop as long as there was some change in the centroids in the last run\n",
    "    while total_diff > epsilon:\n",
    "        # reset total distance to zero\n",
    "        total_diff = 0\n",
    "        # create an array to store the centroid assignments of different entries\n",
    "        centroid_assignments = np.zeros(train_data.shape[0], dtype=float)\n",
    "        # store the centroid assignment of the current entry\n",
    "        centroid_assignment = 0\n",
    "        # assign all entries to their closest centroid\n",
    "        for entry_index in range(train_data.shape[0]):\n",
    "            for centroid_index in range(centroids.shape[0]):\n",
    "                \n",
    "                # if minkowski_metrics(train_data[entry_index], centroids[centroid_index], 2) < minkowski_metrics(train_data[entry_index], centroids[centroid_assignment], 2):\n",
    "                \n",
    "                if np.linalg.norm(train_data[entry_index], centroids[centroid_index]) < np.linalg.norm(train_data[entry_index], centroids[centroid_assignment]):\n",
    "                    centroid_assignment = centroid_index\n",
    "            centroid_assignments[entry_index] = centroid_assignment\n",
    "        # find the average of all the points assigned to each centroid\n",
    "        for centroid_index in range(centroids.shape[0]):\n",
    "            # create an array to store the totals of all features of all assigned entries for the centroid\n",
    "            centroid_ave = np.zeros(centroids.shape[1])\n",
    "            counter = 0\n",
    "            # add the features of each point assigned to the centroid to the total of all features for the centroid\n",
    "            for entry_index in range(train_data.shape[0]):\n",
    "                if centroid_assignments[entry_index] == centroid_index:\n",
    "                    if counter > 0:\n",
    "                        centroid_ave = centroid_ave + train_data[entry_index]\n",
    "                        counter += 1\n",
    "                    else:\n",
    "                        centroid_ave = train_data[entry_index]\n",
    "                        counter += 1\n",
    "            # take the average features of all entries assigned to the cluster, or leave the cluster as is if no entries\n",
    "            # were assigned.\n",
    "            if counter == 0:\n",
    "                centroid_ave = centroids[centroid_index]\n",
    "            else:\n",
    "                centroid_ave = centroid_ave / counter\n",
    "            # add the change in the centroid to the total of all changes in all centroids\n",
    "            # total_diff += minkowski_metrics(centroid_ave, centroids[centroid_index], 2)\n",
    "            total_diff += np.linalg.norm(centroid_ave, centroids[centroid_index])\n",
    "            # reassign the centroid position\n",
    "            centroids[centroid_index] = centroid_ave\n",
    "        # print(total_diff)\n",
    "    return centroids"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68753c1c9f18c930"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def dbscan(data, mininpts, epsilon):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a69d942bb6fa91c1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def precision(predictions, labels):\n",
    "\n",
    "    # the precision function is meant to calculate the precision metric for a specific prediction set. it returns a\n",
    "    # zipped list of the specific precision values for each class\n",
    "\n",
    "    # turn parameters into numpy arrays and get unique classes\n",
    "    labels = np.array(labels)\n",
    "    predictions = np.array(predictions)\n",
    "    classes = np.unique(labels)\n",
    "    class_precisions = []\n",
    "\n",
    "    # for each class in the prediction set calculate the number of true positives divided by the sum of true positives\n",
    "    # and false positives. then append it to the list of all precision values\n",
    "    for class_instance in classes:\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for prediction, label in zip(predictions, labels):\n",
    "            if prediction == class_instance and prediction == label:\n",
    "                tp += 1\n",
    "            elif prediction == class_instance and prediction != label:\n",
    "                fp += 1\n",
    "        if tp + fp != 0:\n",
    "            class_precisions.append(float(tp/(tp + fp)))\n",
    "\n",
    "    return list(zip(classes, class_precisions))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c395216c78f5772"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part 3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "568be323ecb52c9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
